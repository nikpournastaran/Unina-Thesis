\chapter*{Abstract}

Neuro-Symbolic Reasoning, exemplified by frameworks like DeepProbLog, represents a crucial paradigm shift in Natural Language Processing (NLP), 
aiming to overcome the inherent limitations of purely deep learning models, 
particularly in tasks requiring rigorous logic. While neural networks excel at pattern recognition and fluid text generation, 
they often fail at logical consistency, 
exhibiting errors like "hallucination" and poor generalization in complex Textual Entailment and multi-hop reasoning. 
DeepProbLog integrates the pattern-learning capability of neural components with the structured, 
explainable power of Probabilistic Logic Programming, allowing the system to learn from messy data while adhering
 to explicit semantic constraints and providing a traceable, probabilistic proof for its decisions. 
 This fusion promises a new generation of NLP systems that are not only powerful but also more robust, consistent,
  and interpretable. 


  The recent proliferation of deep learning models in Natural Language Processing (NLP) has led to notable advancements and superior performance on various benchmark tasks. However, these models still face significant limitations (Xu and McAuley, 2023). Specifically, they often struggle with tasks that demand intricate reasoning or the fusion of diverse knowledge fragments (Rajani et al., 2020).

These models are also characterized by data inefficiency and issues concerning model generalizability. This is primarily attributed to their inherently opaque nature ("black box") and the lack of a well-defined, structured understanding of the input data they process. Earlier heuristic and black-box methods in text-based policy learning (e.g., LSTM-DQN) and Entity Linking (e.g., BLINK) showed unsatisfactory results, often overfitting the training data (Narasimhan et al., 2015; Wu et al., 2019).

The Neuro-Symbolic Approach as a Solution
To mitigate these critical issues, the integration of neuro-symbolic (NeSy) methods in NLP has been proposed. This approach seeks to combine the strengths of neural networks (for pattern recognition and representation learning) with those of symbolic systems (for structured knowledge, reasoning, and transparency).

Early work demonstrated the potential of this fusion:

(Chaudhury et al., 2021a) explored using the neuro-symbolic approach to solve text-based policy learning.

(Jiang et al., 2021a) proposed a neuro-symbolic model for Entity Linking that achieved a significant increase in the F1 score (over 4%) compared to prior state-of-the-art methods on a benchmark dataset.

These successes have spurred further research and the proposal of various neuro-symbolic works showing appealing performance on benchmark datasets (Gupta et al., 2021; Zhu et al., 2022).

Contribution of the Present Work
This manuscript aims to provide a comprehensive overview of recent advancements in neuro-symbolic methods applied to NLP, addressing the current scarcity of detailed surveys in this early-stage field. While previous work (Hamilton et al., 2022) acknowledged the importance of reasoning in NeSy, this paper offers a more systematic and extensive review.

The primary contributions are:

Comprehensive Review with New Taxonomies: A thorough review of neuro-symbolic methods used in NLP, complete with new taxonomies and a comprehensive comparison across different NeSy tasks.

Theoretical Insights: An analysis of NeSy methods discussing their theoretical advantages, disadvantages, and unresolved challenges for future research.

Wide Coverage and Future Outlook: Examination of emerging trends in NeSy methods, including novel models that integrate neural and symbolic approaches, and offering insights into future research directions and areas for improvement.

\chapter*{Sommario}
Qui puoi inserire il sommario (la traduzione dell'abstract in italiano).
\blindtext[2]